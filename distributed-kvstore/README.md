# ğŸš€ Distributed Key-Value Store System1

## ğŸ“ Tá»•ng Quan Dá»± Ãn

Há»‡ thá»‘ng lÆ°u trá»¯ key-value phÃ¢n tÃ¡n vá»›i kháº£ nÄƒng chá»‹u lá»—i, sá»­ dá»¥ng **gRPC** + **Python** + **Redis**. Há»‡ thá»‘ng cho phÃ©p nhiá»u nodes hoáº¡t Ä‘á»™ng cÃ¹ng nhau, tá»± Ä‘á»™ng phÃ¢n phá»‘i dá»¯ liá»‡u vÃ  Ä‘áº£m báº£o tÃ­nh sáºµn sÃ ng khi cÃ³ node bá»‹ lá»—i.

### ğŸ¯ Má»¥c TiÃªu ChÃ­nh5

- XÃ¢y dá»±ng distributed key-value store tá»« Ä‘áº§u
- Há»c vÃ  apply cÃ¡c concepts: gRPC, Consistent Hashing, Replication, Failure Detection
- Táº¡o há»‡ thá»‘ng cÃ³ kháº£ nÄƒng scale vÃ  fault-tolerant

---

## ğŸ“¦ Codebase Ban Äáº§u

```
distributed-kvstore/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ proto/
â”‚   â”‚   â””â”€â”€ kvstore.proto           # gRPC service definitions
â”‚   â”œâ”€â”€ storage/
â”‚   â”‚   â””â”€â”€ __init__.py
â”‚   â”œâ”€â”€ server.py                   # (empty - cáº§n implement)
â”‚   â”œâ”€â”€ client.py                   # (empty - cáº§n implement)
â”‚   â””â”€â”€ __init__.py
â”œâ”€â”€ config/
â”‚   â”œâ”€â”€ cluster.json                # Config cho 3 nodes
â”‚   â””â”€â”€ redis-*.conf                # Redis configs
â”œâ”€â”€ scripts/
â”‚   â””â”€â”€ start-*.bat/sh              # Scripts Ä‘á»ƒ start cluster
â”œâ”€â”€ requirements.txt                # Python dependencies
â”œâ”€â”€ generate_grpc.py                # Script Ä‘á»ƒ generate gRPC code
â””â”€â”€ README.md                       # File nÃ y
```

### âœ… ÄÃ£ Setup Sáºµn:

1. **Proto Definitions** (`src/proto/kvstore.proto`)
   - Services: `KeyValueStore`, `NodeService`
   - Messages: PUT/GET/DELETE requests & responses
   - Inter-node communication messages

2. **Dependencies** (`requirements.txt`)
   - gRPC + Protobuf
   - Redis client

3. **Config Files**
   - Cluster config cho 3 nodes (ports 8001, 8002, 8003)
   - Redis configs cho 3 instances (ports 6379, 6380, 6381)

---

## ğŸ—ï¸ Kiáº¿n TrÃºc Há»‡ Thá»‘ng

```
       CLIENT
          â”‚
          â–¼ gRPC
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚   Node 1    â”‚â—„â”€â”€â”€â”€â”€â”€â”
    â”‚  (Port 8001)â”‚       â”‚
    â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜       â”‚ gRPC P2P
           â”‚              â”‚ (Replication,
    â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”       â”‚  Heartbeat)
    â”‚   Redis 1   â”‚       â”‚
    â”‚ (Port 6379) â”‚       â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â”‚
                          â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”‚
    â”‚   Node 2    â”‚â—„â”€â”€â”€â”€â”€â”€â”¤
    â”‚  (Port 8002)â”‚       â”‚
    â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜       â”‚
           â”‚              â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”       â”‚
    â”‚   Redis 2   â”‚       â”‚
    â”‚ (Port 6380) â”‚       â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â”‚
                          â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”‚
    â”‚   Node 3    â”‚â—„â”€â”€â”€â”€â”€â”€â”˜
    â”‚  (Port 8003)â”‚
    â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
           â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”
    â”‚   Redis 3   â”‚
    â”‚ (Port 6381) â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“… Development Plan - Chia Tasks cho Team

### ğŸ‘¥ Team Members

- **Linh**: Junior Developer (implement basic features trÆ°á»›c)
- **BÃ¬nh**: Senior Developer (implement core features, integrate & test)

### ğŸ”„ Workflow

1. **Linh** code xong â†’ commit code
2. **BÃ¬nh** review, implement pháº§n quan trá»ng, integrate vá»›i code cá»§a Linh
3. **BÃ¬nh** test Ä‘áº§y Ä‘á»§ theo document
4. âœ… Test pass â†’ Move to next phase
5. âŒ Test fail â†’ Fix bugs â†’ Re-test

---

## ğŸ“‹ Phase 1: Setup & Basic gRPC (1 ngÃ y)

**Goal**: Generate gRPC code, táº¡o server/client template

### ğŸ”§ Tasks

| Task                               | Owner    | Time  | Description                                     |
| ---------------------------------- | -------- | ----- | ----------------------------------------------- |
| 1.1: Generate gRPC code            | **Linh** | 30min | Cháº¡y `python generate_grpc.py` vÃ  verify        |
| 1.2: Create basic server structure | **Linh** | 1h    | Táº¡o `server.py` vá»›i class káº¿ thá»«a gRPC Servicer |
| 1.3: Create basic client           | **Linh** | 1h    | Táº¡o `client.py` vá»›i connect & stub              |
| 1.4: Test server startup           | **BÃ¬nh** | 30min | Verify server start khÃ´ng error                 |

### âœ… Success Criteria (Phase 1)

- [ ] `kvstore_pb2.py` vÃ  `kvstore_pb2_grpc.py` generated thÃ nh cÃ´ng
- [ ] Server start Ä‘Æ°á»£c vÃ  listen trÃªn port 8001
- [ ] Client connect Ä‘Æ°á»£c Ä‘áº¿n server (chÆ°a cáº§n PUT/GET hoáº¡t Ä‘á»™ng)
- [ ] KhÃ´ng cÃ³ import errors

---

## ğŸ“‹ Phase 2: Single Node Storage (2 ngÃ y)

**Goal**: Implement 1 node vá»›i in-memory storage hoáº¡t Ä‘á»™ng Ä‘áº§y Ä‘á»§

### ğŸ”§ Tasks - Day 1

| Task                          | Owner    | Time | Description                                              |
| ----------------------------- | -------- | ---- | -------------------------------------------------------- |
| 2.1: StorageEngine vá»›i dict   | **Linh** | 2h   | Implement `storage_engine.py` vá»›i dict + threading.RLock |
| 2.2: Implement Put handler    | **Linh** | 1h   | Handler `Put()` trong server                             |
| 2.3: Implement Get handler    | **Linh** | 1h   | Handler `Get()` trong server                             |
| 2.4: Implement Delete handler | **Linh** | 1h   | Handler `Delete()` trong server                          |

### ğŸ”§ Tasks - Day 2

| Task                     | Owner    | Time | Description                                         |
| ------------------------ | -------- | ---- | --------------------------------------------------- |
| 2.5: Client test methods | **Linh** | 2h   | Implement `put()`, `get()`, `delete()` trong client |
| 2.6: Add error handling  | **BÃ¬nh** | 1h   | Try-catch trong server handlers                     |
| 2.7: Add logging         | **BÃ¬nh** | 1h   | Setup logging cho debug                             |
| 2.8: Integration test    | **BÃ¬nh** | 2h   | Test Ä‘áº§y Ä‘á»§ PUT/GET/DELETE workflow                 |

### âœ… Success Criteria (Phase 2)

- [ ] PUT key-value thÃ nh cÃ´ng
- [ ] GET key tráº£ vá» Ä‘Ãºng value
- [ ] DELETE key thÃ nh cÃ´ng
- [ ] GET key Ä‘Ã£ delete â†’ NOT FOUND
- [ ] Multiple clients connect cÃ¹ng lÃºc khÃ´ng bá»‹ race condition
- [ ] Logs rÃµ rÃ ng má»—i operation

---

## ğŸ“‹ Phase 3: Multiple Nodes + Consistent Hashing (3 ngÃ y)

**Goal**: 3 nodes phÃ¢n chia data theo Consistent Hashing

### ğŸ”§ Tasks - Day 1

| Task                               | Owner    | Time | Description                            |
| ---------------------------------- | -------- | ---- | -------------------------------------- |
| 3.1: ConsistentHash implementation | **Linh** | 3h   | Implement consistent hashing algorithm |
| 3.2: Hash ring vá»›i virtual nodes   | **Linh** | 2h   | Add virtual nodes Ä‘á»ƒ balance tá»‘t hÆ¡n   |
| 3.3: Unit test ConsistentHash      | **Linh** | 1h   | Test hash distribution                 |

### ğŸ”§ Tasks - Day 2

| Task                              | Owner    | Time | Description                           |
| --------------------------------- | -------- | ---- | ------------------------------------- |
| 3.4: MembershipManager            | **Linh** | 2h   | Load cluster config, manage node list |
| 3.5: Determine owner node         | **BÃ¬nh** | 2h   | Logic xÃ¡c Ä‘á»‹nh key thuá»™c node nÃ o     |
| 3.6: Implement request forwarding | **BÃ¬nh** | 3h   | Forward request Ä‘áº¿n Ä‘Ãºng node         |

### ğŸ”§ Tasks - Day 3

| Task                      | Owner    | Time | Description                          |
| ------------------------- | -------- | ---- | ------------------------------------ |
| 3.7: NodeService handlers | **BÃ¬nh** | 2h   | Implement ForwardPut/Get/Delete      |
| 3.8: Start 3 nodes script | **Linh** | 1h   | Script Ä‘á»ƒ start 3 nodes dá»… dÃ ng      |
| 3.9: Test distribution    | **BÃ¬nh** | 3h   | Test data phÃ¢n chia Ä‘á»u giá»¯a 3 nodes |

### âœ… Success Criteria (Phase 3)

- [ ] Start 3 nodes thÃ nh cÃ´ng
- [ ] Client connect Ä‘áº¿n báº¥t ká»³ node nÃ o
- [ ] PUT key â†’ Data lÆ°u vÃ o Ä‘Ãºng owner node
- [ ] GET key tá»« node khÃ¡c â†’ Forward vÃ  tráº£ vá» Ä‘Ãºng
- [ ] Data distribution tÆ°Æ¡ng Ä‘á»‘i Ä‘á»u (~33% má»—i node)

---

## ğŸ“‹ Phase 4: Replication (2 ngÃ y)

**Goal**: Má»—i key cÃ³ 2 copies (primary + 1 replica)

### ğŸ”§ Tasks - Day 1

| Task                        | Owner    | Time | Description                         |
| --------------------------- | -------- | ---- | ----------------------------------- |
| 4.1: ReplicationManager     | **Linh** | 2h   | Class quáº£n lÃ½ replication           |
| 4.2: Determine replica node | **Linh** | 2h   | Logic chá»n replica node (successor) |
| 4.3: Replicate RPC call     | **Linh** | 2h   | Gá»­i ReplicateRequest Ä‘áº¿n replica    |

### ğŸ”§ Tasks - Day 2

| Task                          | Owner    | Time | Description                              |
| ----------------------------- | -------- | ---- | ---------------------------------------- |
| 4.4: Handle Replicate request | **BÃ¬nh** | 2h   | Xá»­ lÃ½ ReplicateRequest trong NodeService |
| 4.5: Update PUT flow          | **BÃ¬nh** | 2h   | PUT â†’ Save local + Replicate             |
| 4.6: Update DELETE flow       | **BÃ¬nh** | 1h   | DELETE â†’ Delete local + Replicate delete |
| 4.7: Test replication         | **BÃ¬nh** | 2h   | Verify má»—i key cÃ³ 2 copies               |

### âœ… Success Criteria (Phase 4)

- [ ] PUT key â†’ 2 nodes cÃ³ data (primary + replica)
- [ ] Verify data tá»“n táº¡i trÃªn cáº£ 2 nodes
- [ ] DELETE key â†’ XÃ³a trÃªn cáº£ 2 nodes
- [ ] Replication khÃ´ng block client (async náº¿u cÃ³ thá»ƒ)

---

## ğŸ“‹ Phase 5: Failure Detection (2 ngÃ y)

**Goal**: PhÃ¡t hiá»‡n node failure vÃ  redirect requests

**Note**: Phase phá»©c táº¡p, cáº§n senior handle toÃ n bá»™

### ğŸ”§ Tasks - Day 1

| Task                    | Owner    | Time | Description                              |
| ----------------------- | -------- | ---- | ---------------------------------------- |
| 5.1: Heartbeat sender   | **BÃ¬nh** | 2h   | Thread gá»­i heartbeat má»—i 5 giÃ¢y          |
| 5.2: Heartbeat receiver | **BÃ¬nh** | 2h   | Handler nháº­n heartbeat, update timestamp |
| 5.3: Failure detector   | **BÃ¬nh** | 2h   | Check timeout (15 giÃ¢y)                  |

### ğŸ”§ Tasks - Day 2

| Task                       | Owner    | Time | Description                     |
| -------------------------- | -------- | ---- | ------------------------------- |
| 5.4: Update hash ring      | **BÃ¬nh** | 2h   | Remove failed node khá»i ring    |
| 5.5: Redirect to replica   | **BÃ¬nh** | 2h   | GET tá»« replica khi primary fail |
| 5.6: Test failure scenario | **BÃ¬nh** | 3h   | Kill 1 node â†’ Verify reads work |

### âœ… Success Criteria (Phase 5)

- [ ] Nodes gá»­i heartbeat thÃ nh cÃ´ng
- [ ] Kill node 1 â†’ Há»‡ thá»‘ng detect trong 15 giÃ¢y
- [ ] GET key cá»§a node 1 â†’ Äá»c tá»« replica
- [ ] PUT requests redirect Ä‘áº¿n available nodes

---

## ğŸ“‹ Phase 6: Data Recovery (2 ngÃ y)

**Goal**: Node restart cÃ³ thá»ƒ recover data

**Note**: Phase quan trá»ng, cáº§n senior handle toÃ n bá»™

### ğŸ”§ Tasks - Day 1

| Task                        | Owner    | Time | Description                      |
| --------------------------- | -------- | ---- | -------------------------------- |
| 6.1: GetSnapshot handler    | **BÃ¬nh** | 2h   | Handler tráº£ vá» all data          |
| 6.2: Snapshot serialization | **BÃ¬nh** | 2h   | Efficient batch transfer         |
| 6.3: Recovery on startup    | **BÃ¬nh** | 2h   | Detect restart, request snapshot |

### ğŸ”§ Tasks - Day 2

| Task                           | Owner    | Time | Description                                |
| ------------------------------ | -------- | ---- | ------------------------------------------ |
| 6.4: Load snapshot to storage  | **BÃ¬nh** | 2h   | Parse vÃ  load data vÃ o storage             |
| 6.5: Test recovery             | **BÃ¬nh** | 3h   | Stop node â†’ Delete data â†’ Restart â†’ Verify |
| 6.6: Handle concurrent updates | **BÃ¬nh** | 2h   | Conflict resolution (last-write-wins)      |

### âœ… Success Criteria (Phase 6)

- [ ] Stop node â†’ Delete storage
- [ ] Restart node â†’ Auto request snapshot
- [ ] Data recovered hoÃ n toÃ n
- [ ] Node rejoin cluster vÃ  hoáº¡t Ä‘á»™ng bÃ¬nh thÆ°á»ng

---

## ğŸ“‹ Phase 7: Redis Integration (Optional - 1 ngÃ y)

**Goal**: Chuyá»ƒn tá»« in-memory dict sang Redis persistent storage

**Note**: Phase optional, senior tá»± handle náº¿u cÃ²n thá»i gian

### ğŸ”§ Tasks

| Task                        | Owner    | Time | Description                                |
| --------------------------- | -------- | ---- | ------------------------------------------ |
| 7.1: Redis connection       | **BÃ¬nh** | 1h   | Setup Redis connection pool                |
| 7.2: Update StorageEngine   | **BÃ¬nh** | 2h   | Replace dict operations vá»›i Redis commands |
| 7.3: Config Redis instances | **BÃ¬nh** | 1h   | Start 3 Redis instances                    |
| 7.4: Test persistence       | **BÃ¬nh** | 2h   | Restart node â†’ Data váº«n cÃ²n                |

### âœ… Success Criteria (Phase 7)

- [ ] Data lÆ°u trong Redis thay vÃ¬ dict
- [ ] Restart node â†’ Data persist (khÃ´ng máº¥t)
- [ ] Performance tá»‘t (Redis in-memory)

---

## ğŸ§ª Testing Checklist

Sau má»—i phase, **BÃ¬nh** pháº£i test Ä‘áº§y Ä‘á»§:

### Phase 2 Test:

```bash
# Terminal 1
python src/server.py 8001

# Terminal 2
python src/client.py
# Expected: PUT/GET/DELETE thÃ nh cÃ´ng
```

### Phase 3 Test:

```bash
# Start 3 nodes
python src/server.py 8001 &
python src/server.py 8002 &
python src/server.py 8003 &

# Test client connect random node
python src/client.py --node-port 8002
# Expected: Data routing Ä‘Ãºng
```

### Phase 4 Test:

```bash
# PUT data
# Check trÃªn 2 nodes cÃ³ data
# Expected: 2 copies tá»“n táº¡i
```

### Phase 5 Test:

```bash
# Start 3 nodes
# Kill node 1 (Ctrl+C)
# GET data cá»§a node 1
# Expected: Read tá»« replica thÃ nh cÃ´ng
```

### Phase 6 Test:

```bash
# Stop node 2
# Delete node 2 data
# Restart node 2
# Check data
# Expected: Data recovered
```

---

## ğŸ“Š Timeline Summary

| Phase     | Duration    | Linh Tasks | BÃ¬nh Tasks | Total   |
| --------- | ----------- | ---------- | ---------- | ------- |
| Phase 1   | 1 day       | 2.5h       | 0.5h       | 3h      |
| Phase 2   | 2 days      | 7h         | 4h         | 11h     |
| Phase 3   | 3 days      | 8h         | 10h        | 18h     |
| Phase 4   | 2 days      | 6h         | 7h         | 13h     |
| Phase 5   | 2 days      | 0h         | 13h        | 13h     |
| Phase 6   | 2 days      | 0h         | 13h        | 13h     |
| Phase 7   | 1 day (opt) | 0h         | 6h         | 6h      |
| **Total** | **13 days** | **23.5h**  | **53.5h**  | **77h** |

### ğŸ“Œ PhÃ¢n TÃ­ch Distribution:

**Linh (Junior - 23.5h):**

- Phase 1-4: Setup, basic features, foundation work
- Focus: Learning gRPC, implementing basic storage, testing

**BÃ¬nh (Senior - 53.5h):**

- Phase 1-4: Integration, advanced features, testing
- Phase 5-7: **100% ownership** - Critical features (failure detection, recovery, Redis)
- Rationale: Phases cuá»‘i phá»©c táº¡p, cáº§n senior experience

---

## ğŸš€ Quick Start

### 1. Setup Dependencies

```bash
pip install -r requirements.txt
```

### 2. Generate gRPC Code

```bash
python generate_grpc.py
```

### 3. Start Server (Phase 2+)

```bash
python src/server.py 8001
```

### 4. Run Client Test

```bash
python src/client.py
```

---

## ğŸ“ Notes

- **Code review**: BÃ¬nh review code cá»§a Linh trÆ°á»›c khi integrate
- **Testing**: KhÃ´ng skip testing, phase nÃ o chÆ°a pass khÃ´ng sang phase khÃ¡c
- **Documentation**: Update README náº¿u cÃ³ thay Ä‘á»•i lá»›n
- **Git workflow**: Má»—i phase táº¡o 1 branch riÃªng, merge sau khi test pass

---

## ğŸ¯ Success Metrics

Project hoÃ n thÃ nh khi:

- âœ… All phases test pass
- âœ… 3 nodes hoáº¡t Ä‘á»™ng Ä‘á»“ng thá»i
- âœ… Failure tolerance hoáº¡t Ä‘á»™ng
- âœ… Data recovery hoáº¡t Ä‘á»™ng
- âœ… Code clean, cÃ³ comments
- âœ… README Ä‘áº§y Ä‘á»§ hÆ°á»›ng dáº«n

**Good luck team! ğŸš€**
